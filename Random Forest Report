Main
The random forest algorithm was tested on the images that were trying to fool the majority classifier. As mentioned before, the algorithm was able to train the data, but after testing it, it did not fool the classifier. This may have been because we changed the less important pixels in the image. If the algorithm would have worked, it would have fooled the classifier by changing less than 1 percent of the image. The big problem we had when trying to do this was limiting the changing of pixels by only 1 percent or less. Since this was such a small amount, the algorithm could not detect the image correctly. Another unforeseen challenge was testing the algorithm. Every time we went to test, the time it took for the code the run was over 10 minutes. This caused a lot of crashes while testing, causing the failure of the algorithm.

Runtime and Wall Complexity
In general run times are dependent on the size and complexity of the data. In the cases of training and testing, the run times were significantly different. When training the data using the random forest algorithm, our group saw that it took a very long time. This is probably because it has to create many different decision trees. Even though we did not get the algorithm to fool the majority classifier, the run time for the testing was much faster. Because the decision trees are already built at this time, it can quickly go through all of them to predict the entire random forest. This is good for our project because we needed to have the algorithm fool the majority classifier in under 10 seconds after it was trained.

Performance
After creating the random forest algorithm, it was concluded that the algorithm did not fool the majority classifier. Even though we tried to change pixels in the image, the algorithm did not work as it should have. One of the main reasons for this was that we were limited to changing less than 1 percent of the pixels only. Because the random forest algorithm makes multiple different decision trees, it has to run through each of them while testing. This caused the testing to occur for a long time. While the implementation of this algorithm was done as tasked, in the end, it failed to fool the classifier. 

Justification
The Random Forest Algorithm is one of the most common and useful machine learning algorithms. A very useful trait of this algorithm is that it can handle data containing continuous variables and categorical variables. Overall, random forest algorithms tend to have high accuracy, so in our project, where the goal is to fool the majority classifier then, it is important that we get the most accurate results. Because it builds multiple individual decision trees based on the subset of the training data, it can alleviate the problem of over fitting. The random forest also gives feature importance. In our case, we could see which pixels of the image were most or least important. From that, we could decide which pixels to change to fool the classifier. Lastly, random forest algorithms do well when there is a lot of noise in the data. For example, if there were outliers or empty data, it could weed out those points much better than other machine learning algorithms. 

